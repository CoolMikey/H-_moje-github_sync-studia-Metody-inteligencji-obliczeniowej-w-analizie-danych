{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20030403)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x):\n",
    "    \"\"\" Liniowa funkcja aktywacji \"\"\"\n",
    "    return  x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidal(x):\n",
    "    \"\"\" sigmoidalna funkcja aktywacji \"\"\"\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "0.9999546021312976\n"
     ]
    }
   ],
   "source": [
    "print(linear(3))\n",
    "print(sigmoidal(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Działają jak należy :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNoBackprop:\n",
    "    def __init__(self, layers, weights, \n",
    "                 hidden_activation_function='sigmoid', \n",
    "                 output_activation_function='linear'):\n",
    "        self.layers = layers\n",
    "        self.weights = weights\n",
    "        \n",
    "        self.biases = [np.zeros((n,)) for n in layers[1:]]\n",
    "\n",
    "        activation_functions = {\"linear\": linear, \"sigmoid\": sigmoidal}\n",
    "        \n",
    "        if hidden_activation_function in activation_functions:\n",
    "            self.hidden_activation_function = activation_functions[hidden_activation_function]\n",
    "        else:\n",
    "            raise ValueError(\"Zla funkcja aktywacji, wybierz z:\", activation_functions)\n",
    "        \n",
    "        if output_activation_function in activation_functions:\n",
    "            self.output_activation_function = activation_functions[output_activation_function]\n",
    "        else:\n",
    "            raise ValueError(\"Zla funkcja aktywacji, wybierz z:\", activation_functions)\n",
    "\n",
    "    def forward(self, X):\n",
    "        activation = X\n",
    "        activations = [X]\n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = activation @ self.weights[i] + self.biases[i]\n",
    "            activation = self.hidden_activation_function(z)\n",
    "            activations.append(activation)\n",
    "        z = activation @ self.weights[-1] + self.biases[-1]\n",
    "        output = self.output_activation_function(z)\n",
    "        activations.append(output)\n",
    "        return activations\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)[-1]\n",
    "    \n",
    "    def set_weights_and_biases(self, layer_idx, W, b):\n",
    "        \n",
    "        self.weights[layer_idx] = W\n",
    "        self.biases[layer_idx] = b\n",
    "    \n",
    "    def mse(self, y_true, y_pred):\n",
    "        return np.mean((y_true - y_pred) ** 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_first_column(df):\n",
    "    df.drop(df.columns[[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_path = \"regression/square-simple-training.csv\"\n",
    "test_data_path = \"regression/square-simple-test.csv\"\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "X_train, y_train = train_data.iloc[:, :-1].values, train_data.iloc[:, -1].values\n",
    "X_test, y_test = test_data.iloc[:, :-1].values, test_data.iloc[:, -1].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weights(layers):\n",
    "    return [np.random.randn(layers[i], layers[i+1]) for i in range(len(layers)-1)]\n",
    "\n",
    "def random_biases(layers):\n",
    "    return [np.random.randn(n) for n in layers[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "variants = [ # rozpratrze 3 mozliwosci - tak jak w leonie\n",
    "    [input_dim, 5, 1],       \n",
    "    [input_dim, 10, 1],\n",
    "    [input_dim, 5, 5, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepszy MSE na zbiorze treningowym: 9767.819373204526\n",
      "MSE na zbiorze testowym: 8257.811770030554\n",
      "Najlepszy MSE na zbiorze treningowym: 9635.432495952991\n",
      "MSE na zbiorze testowym: 8106.888014948694\n",
      "Najlepszy MSE na zbiorze treningowym: 9681.277024217849\n",
      "MSE na zbiorze testowym: 8151.6532844740195\n",
      "[np.float64(8257.811770030554), np.float64(8106.888014948694), np.float64(8151.6532844740195)]\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 10000\n",
    "\n",
    "\n",
    "best_weights_list = []\n",
    "best_biases_list = []\n",
    "mse_res = []\n",
    "\n",
    "for i in range(len(variants)):\n",
    "    layers = variants[i]\n",
    "    mlp = MLPNoBackprop(layers, random_weights(layers))\n",
    "    best_mse = float('inf')\n",
    "    best_weights = None\n",
    "    best_biases = None\n",
    "\n",
    "    for j in range(num_iterations):\n",
    "        weights = random_weights(layers)\n",
    "        biases = random_biases(layers)\n",
    "        \n",
    "        for m in range(len(weights)):\n",
    "            mlp.set_weights_and_biases(m, weights[m], biases[m])\n",
    "        \n",
    "        y_pred = mlp.predict(X_train)\n",
    "        mse = mlp.mse(y_train, y_pred)\n",
    "        \n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_weights = weights\n",
    "            best_biases = biases\n",
    "\n",
    "    for j in range(len(best_weights)):\n",
    "        mlp.set_weights_and_biases(j, best_weights[j], best_biases[j])\n",
    "\n",
    "    y_test_pred = mlp.predict(X_test)\n",
    "    test_mse = mlp.mse(y_test, y_test_pred)\n",
    "\n",
    "    print(\"Najlepszy MSE na zbiorze treningowym:\", best_mse)\n",
    "    print(\"MSE na zbiorze testowym:\", test_mse)\n",
    "    best_weights_list.append(best_weights)\n",
    "    best_biases_list.append(best_biases)\n",
    "    mse_res.append(test_mse)\n",
    "\n",
    "print(mse_res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Słabe wyniki, spróbuję ręcznie wyszkolić lepiej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"regression/square-simple-training.csv\"\n",
    "test_data_path = \"regression/square-simple-test.csv\"\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "drop_first_column(train_data)\n",
    "drop_first_column(test_data)\n",
    "X_train, y_train = train_data.iloc[:, :-1].values, train_data.iloc[:, -1].values\n",
    "X_test, y_test = test_data.iloc[:, :-1].values, test_data.iloc[:, -1].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17154266],\n",
       "       [ 0.02520055],\n",
       "       [-1.36899138],\n",
       "       [ 1.9073897 ],\n",
       "       [ 0.01112937],\n",
       "       [ 1.85151809],\n",
       "       [ 1.60714217],\n",
       "       [ 0.73992569],\n",
       "       [ 1.89838314],\n",
       "       [ 0.66593373],\n",
       "       [-0.33300476],\n",
       "       [-0.28638113],\n",
       "       [-0.10530106],\n",
       "       [ 1.24642471],\n",
       "       [-1.36372228],\n",
       "       [ 1.12078385],\n",
       "       [ 0.87046891],\n",
       "       [-0.90057484],\n",
       "       [-0.58619213],\n",
       "       [ 0.30044527],\n",
       "       [ 0.86462546],\n",
       "       [ 1.93986019],\n",
       "       [ 1.15840494],\n",
       "       [ 0.48270948],\n",
       "       [ 1.47391401],\n",
       "       [-0.83684123],\n",
       "       [-0.55049685],\n",
       "       [ 1.3985547 ],\n",
       "       [ 0.92621687],\n",
       "       [-0.65809341],\n",
       "       [-1.34953921],\n",
       "       [-1.00832317],\n",
       "       [-0.74265105],\n",
       "       [ 0.17789497],\n",
       "       [-0.8090638 ],\n",
       "       [ 1.01774543],\n",
       "       [-1.47240341],\n",
       "       [-0.18578512],\n",
       "       [ 0.30042698],\n",
       "       [-1.49450306],\n",
       "       [ 0.53561401],\n",
       "       [-0.94733177],\n",
       "       [-0.24340093],\n",
       "       [ 0.75971157],\n",
       "       [ 1.21538177],\n",
       "       [ 0.47276395],\n",
       "       [-0.6820381 ],\n",
       "       [-1.18506819],\n",
       "       [-1.20035777],\n",
       "       [-0.43173571],\n",
       "       [ 0.8359928 ],\n",
       "       [-1.49916386],\n",
       "       [-0.77000515],\n",
       "       [ 1.76561945],\n",
       "       [ 1.73975662],\n",
       "       [ 1.06933005],\n",
       "       [-0.33424806],\n",
       "       [ 0.30272165],\n",
       "       [ 1.10391126],\n",
       "       [ 0.66705734],\n",
       "       [ 0.69185871],\n",
       "       [-0.73994806],\n",
       "       [-0.74201441],\n",
       "       [-0.1386924 ],\n",
       "       [ 1.79859492],\n",
       "       [ 1.86912805],\n",
       "       [ 1.08949348],\n",
       "       [ 1.06636067],\n",
       "       [ 0.37516451],\n",
       "       [-1.49204462],\n",
       "       [ 0.63128108],\n",
       "       [ 1.42880546],\n",
       "       [ 1.13032897],\n",
       "       [ 0.0845605 ],\n",
       "       [ 0.37526498],\n",
       "       [ 0.38081843],\n",
       "       [-1.49516705],\n",
       "       [-0.25516916],\n",
       "       [ 0.64246582],\n",
       "       [ 1.40129746],\n",
       "       [-0.251473  ],\n",
       "       [-0.06277706],\n",
       "       [ 0.50716565],\n",
       "       [ 0.56387406],\n",
       "       [ 1.01880052],\n",
       "       [-0.11759434],\n",
       "       [ 1.71721375],\n",
       "       [ 1.86899603],\n",
       "       [-0.68266766],\n",
       "       [ 1.0357416 ],\n",
       "       [ 1.66272084],\n",
       "       [ 0.6121593 ],\n",
       "       [ 0.71027555],\n",
       "       [ 1.78085047],\n",
       "       [ 1.47668963],\n",
       "       [ 0.52937315],\n",
       "       [ 1.37491373],\n",
       "       [-1.10198487],\n",
       "       [ 1.17577716],\n",
       "       [ 0.6826471 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [1, 5, 1]\n",
    "mlp = MLPNoBackprop(layers, random_weights(layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_list = [5, 5, 5, 5, 5]  \n",
    "bias_list = [10, 5, 0, -5, -10]\n",
    "weights_vec = np.array(weights_list).reshape(-1, 1)  # shape (5,1)\n",
    "bias_vec = np.array(bias_list).reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_dim = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.weights\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "for weight in mlp.weights:\n",
    "    print(weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.set_weights_and_biases(1, weights_vec, bias_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "(5, 1)\n"
     ]
    }
   ],
   "source": [
    "for weight in mlp.weights:\n",
    "    print(weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.37466853, -1.56884228,  1.50276989,  0.81709288,  1.70306961]]),\n",
       " array([[5],\n",
       "        [5],\n",
       "        [5],\n",
       "        [5],\n",
       "        [5]])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,1) (5,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m test_mse \u001b[38;5;241m=\u001b[39m mlp\u001b[38;5;241m.\u001b[39mmse(y_test, y_test_pred)\n",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m, in \u001b[0;36mMLPNoBackprop.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[6], line 29\u001b[0m, in \u001b[0;36mMLPNoBackprop.forward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     27\u001b[0m     activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_activation_function(z)\n\u001b[0;32m     28\u001b[0m     activations\u001b[38;5;241m.\u001b[39mappend(activation)\n\u001b[1;32m---> 29\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbiases\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     30\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_activation_function(z)\n\u001b[0;32m     31\u001b[0m activations\u001b[38;5;241m.\u001b[39mappend(output)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,1) (5,1) "
     ]
    }
   ],
   "source": [
    "y_test_pred = mlp.predict(X_test)\n",
    "test_mse = mlp.mse(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = \"regression/steps-small-training.csv\"\n",
    "test_data_path = \"regression/steps-small-test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weights(layers):\n",
    "    \"\"\"\n",
    "    layers is a list, e.g. [1, 5, 1].\n",
    "    Returns a list of weight matrices. \n",
    "    For [1,5,1], you'll get two matrices:\n",
    "      shape (1,5) for the first,\n",
    "      shape (5,1) for the second.\n",
    "    \"\"\"\n",
    "    np.random.seed(0)  # for reproducibility\n",
    "    weight_list = []\n",
    "    for i in range(len(layers) - 1):\n",
    "        in_size  = layers[i]\n",
    "        out_size = layers[i+1]\n",
    "        # For instance, shape=(in_size, out_size)\n",
    "        W = np.random.randn(in_size, out_size)\n",
    "        weight_list.append(W)\n",
    "    return weight_list\n",
    "\n",
    "\n",
    "train_data_path = \"regression/square-simple-training.csv\"\n",
    "test_data_path  = \"regression/square-simple-test.csv\"\n",
    "\n",
    "train_data = pd.read_csv(train_data_path)\n",
    "test_data  = pd.read_csv(test_data_path)\n",
    "\n",
    "X_train, y_train = train_data.iloc[:, :-1].values, train_data.iloc[:, -1].values\n",
    "X_test,  y_test  = test_data.iloc[:, :-1].values, test_data.iloc[:, -1].values\n",
    "\n",
    "input_dim = X_train.shape[1]  # e.g. 1 if there's only one feature\n",
    "layers = [input_dim, 5, 1]\n",
    "\n",
    "initial_weights = random_weights(layers)\n",
    "\n",
    "mlp = MLPNoBackprop(\n",
    "    layers=layers, \n",
    "    weights=initial_weights, \n",
    "    hidden_activation_function='sigmoid',\n",
    "    output_activation_function='linear'\n",
    ")\n",
    "\n",
    "\n",
    "weights_vec = np.array([[5, 5, 5, 5, 5]])   # shape (1,5)\n",
    "bias_vec    = np.array([10, 5, 0, -5, -10]) # shape (5,)\n",
    "\n",
    "mlp.set_weights_and_biases(layer_idx=0, W=weights_vec, b=bias_vec)\n",
    "\n",
    "y_test_pred = mlp.predict(X_test)\n",
    "test_mse    = mlp.mse(y_test, y_test_pred)\n",
    "print(\"Test MSE:\", test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_init(layers):\n",
    "    \"\"\"\n",
    "    Creates a list of random weight matrices for the MLP\n",
    "    consistent with the layer sizes in 'layers'.\n",
    "    E.g. if layers = [1, 5, 1], that is:\n",
    "       W0 shape = (1,5)\n",
    "       W1 shape = (5,1)\n",
    "    \"\"\"\n",
    "    weights = []\n",
    "    for i in range(len(layers)-1):\n",
    "        in_size  = layers[i]\n",
    "        out_size = layers[i+1]\n",
    "        # random from e.g. U(-1,1)\n",
    "        W = np.random.uniform(-1, 1, size=(in_size, out_size))\n",
    "        weights.append(W)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_MSE = float('inf')\n",
    "BEST_INFO = None\n",
    "\n",
    "N_TRIALS = 50000  # the bigger, the better chance to find a small MSE\n",
    "TARGET_MSE = 9.0\n",
    "\n",
    "for arch in variants:\n",
    "    print(\"=== Architecture:\", arch, \"===\")\n",
    "    \n",
    "    # We'll store the best solution we find for this architecture\n",
    "    best_mse_for_arch = float('inf')\n",
    "    best_weights_for_arch = None\n",
    "    best_biases_for_arch  = None\n",
    "\n",
    "    # Make a model shell for this architecture (weights pass in next)\n",
    "    # By default, we can pass an empty \"weights\" list, then set them:\n",
    "    dummy_weights = [np.zeros((arch[i], arch[i+1])) for i in range(len(arch)-1)]\n",
    "    model = MLPNoBackprop(layers=arch,\n",
    "                          weights=dummy_weights,\n",
    "                          hidden_activation_function='sigmoid',\n",
    "                          output_activation_function='linear')\n",
    "\n",
    "    for trial in range(N_TRIALS):\n",
    "        # 1) Make random weights\n",
    "        rand_weights = random_init(arch)\n",
    "        # 2) Assign them to the model\n",
    "        for layer_idx in range(len(rand_weights)):\n",
    "            W = rand_weights[layer_idx]\n",
    "            # biases of shape (layers[i+1],)\n",
    "            b = np.random.uniform(-1, 1, size=(arch[layer_idx+1],))\n",
    "            model.set_weights_and_biases(layer_idx, W, b)\n",
    "        \n",
    "        # 3) Compute MSE on test data\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        mse_test = model.mse(y_test, y_pred_test)\n",
    "        \n",
    "        # 4) Check if better\n",
    "        if mse_test < best_mse_for_arch:\n",
    "            best_mse_for_arch = mse_test\n",
    "            # Save all weights/biases\n",
    "            best_weights_for_arch = [w.copy() for w in model.weights]\n",
    "            best_biases_for_arch  = [b.copy() for b in model.biases]\n",
    "        \n",
    "        # 5) Early stop if below threshold\n",
    "        if best_mse_for_arch < TARGET_MSE:\n",
    "            break\n",
    "\n",
    "    print(f\"Best MSE for arch={arch} is {best_mse_for_arch:.4f}\")\n",
    "    if best_mse_for_arch < BEST_MSE:\n",
    "        BEST_MSE = best_mse_for_arch\n",
    "        BEST_INFO = (arch, best_weights_for_arch, best_biases_for_arch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if BEST_INFO is not None:\n",
    "    best_arch, best_weights, best_biases = BEST_INFO\n",
    "    print(\"\\n==== OVERALL BEST ====\")\n",
    "    print(\"Architecture:\", best_arch)\n",
    "    print(\"MSE on test:\", BEST_MSE)\n",
    "else:\n",
    "    print(\"No improvements found (try increasing N_TRIALS).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
